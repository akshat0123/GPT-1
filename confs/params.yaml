window_size: &window_size 16
vocab_size: &vocab_size 10141
device: &device 'cpu'


tokenizer: 
    path: "/home/apgpu/Programs/Decoders/checkpoints/tokenizer.pickle"

dataset:
    datapath: '/home/akshat/Programs/Decoders/data/data.txt'
    linecount: 100000

collator:
    window_size: *window_size
    vocab_size: *vocab_size
    device: *device

loader:
    drop_last: True
    batch_size: 1028
    shuffle: True 

model:
    vocab_size: *vocab_size
    embedding_size: 128
    window_size: *window_size
    d_k: 64
    d_v: 64
    n_heads: 2
    hidden: 256
    n_blocks: 2
    device: *device

optimizer:
    lr: 0.01
    weight_decay: 0.01

scheduler:
    T_max: 10

epochs: 10

checkpoint: "/home/apgpu/Programs/Decoders/checkpoints"
