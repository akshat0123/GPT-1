tokenizer:
    countpath: "/home/akshat/Programs/Decoders/data/counts.txt"
    start: "<START>"
    unk: "<UNK>"
    pad: "<PAD>"
    end: "<END>"
    vocab: 1000
    window: 128

dataset:
    datapath: "/home/akshat/Programs/Decoders/data/data.txt"
    linecount: 500

loader:
    batch_size: 32
