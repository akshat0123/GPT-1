tokenizer:
    countpath: "/home/akshat/Programs/Decoders/data/counts.txt"
    start: "<START>"
    unk: "<UNK>"
    pad: "<PAD>"
    end: "<END>"
    vocab: 1000
    window: 16

dataset:
    datapath: "/home/akshat/Programs/Decoders/data/data.txt"
    linecount: 1269

loader:
    drop_last: True
    batch_size: 32
    shuffle: True

model:
    v: 1000
    w: 16
    d: 128
    dk: 64
    n_heads: 2
    hidden: 256
    n_blocks: 2
    dropout: 0.1
    device: 'cpu'

optimizer:
    lr: 1.0
    weight_decay: 0.01

scheduler:
    T_max: 10

epochs: 10

checkpoint: "/home/akshat/Programs/Decoders/checkpoints"
